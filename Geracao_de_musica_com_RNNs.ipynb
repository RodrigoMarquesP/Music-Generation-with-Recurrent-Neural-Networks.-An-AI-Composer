{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Geracao_de_musica_com_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+7aKffeBy6RXsRzrWMVyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/blob/master/Geracao_de_musica_com_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rklo1xmOBss-"
      },
      "source": [
        "Este projeto é inspirado no curso 6.S191 do MIT de 2020, incluindo o uso dos dados de treinamento, porém ele é extremamente reprodutível com qualquer outro conjunto de dados.\n",
        "\n",
        "Obs: O texto se atém ao máximo à língua portuguesa, mas para manter os termos mais frequentemente encontrados na literatura e comunidade, utilizaremos as palavras ***input/output*** para ***entrada/saída*** da rede respectivamente, bem como usaremos ***dataset*** para falar sobre o ***conjunto de dados***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEMnTfVJy1nY"
      },
      "source": [
        "# ***Redes Neurais Recorrentes como uma solução para problemas sequenciais***\n",
        "\n",
        "Um problema sequencial no nicho de dados é um problema envolvendo dados sequenciais de qualquer tipo - como um vetor de informações -, onde os termos da sequência tem relações de significado, estado, e ordem com outros. Tal situação pode trazer consigo diversos problemas para os modelos tradicionais de aprendizado de máquina e deep learning, bem como:\n",
        "\n",
        "\n",
        "*   O **comprimento** da sequência pode ser **variável**.\n",
        "*   A **ordem** dos termos pode ser **variável**, mudando ou não seu significado/valor.\n",
        "*   **Relações importantes** podem estar **distantes** na sequência, não permitindo que os modelos considerem apenas um comprimento fixo para todos inputs.\n",
        "*   **Um termo** pode ter seu **significado e/ou relevância diferentes** dependendo de sua posição e/ou dos outros termos que o cercam.\n",
        "\n",
        "Tratar esses pontos nos permite diversas aplicações, como previsões climáticas, previsão de preços de ações, predição de rastreamento de objetos (essencial para carros autônomos), geração de texto, classificação de sentimentos, geração de músicas, e muitos outros.\n",
        "\n",
        "   \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/climatic.gif\"> \n",
        "</p>  \n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/stock_prices.png\" width=650>\n",
        "</p> \n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/trajectory_prediction.gif\" width=650>\n",
        "</p>\n",
        "\n",
        "Para resolver esses problemas, a RNN processa ao longo da sequência, item por item, prevendo o próximo elemento, como a próxima letra, palavra, nota musical (na geração de músicas), número, vetor, etc. Com esta técnica, a retropropagação (backpropagation) é computada ao longo do tempo, fazendo com que o estado interno da rede (*h*) seja importante para a previsão (*y*).\n",
        "\n",
        "Abaixo está uma comparação entre o modelo de rede neural padrão e uma arquitetura específica de RNN para servir de exemplo - esta será usada na geração de músicas pois seu output é uma sequência de qualquer comprimento desejado, entretanto existem diversas outras arquiteturas.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/rnn.jpg\" width=700>\n",
        "</p>\n",
        "\n",
        "Então, após treinar esta arquitetura com sequências de notas musicais, podemos prever notas seguintes que nunca existiram nas músicas de treino, gerando uma melodia totalmente nova, uma composição genuína de um modelo de deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az2PKoZc-Vts"
      },
      "source": [
        "# ***Criação do modelo***\n",
        "\n",
        "Antes mesmo de começar o projeto, vá até a opção de *Ambiente de execução* na barra de opções e altere o ambiente de execução para GPU, o que acelerará as operações computacionais.\n",
        "\n",
        "\n",
        "## ***Carregando os pacotes:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnfmpTjRy0xc"
      },
      "source": [
        "# Especificando a versão do tensorflow\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# importando os pacotes\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "# O módulo tqdm mostra uma barra de progresso no nosso loop de treino\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Para o conjunto de dados de treinamento usaremos o dataset de músicas folclóricas irlandesas do MIT 6.S191, sob licença:\n",
        "\n",
        "# Copyright 2020 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
        "# reference:\n",
        "#\n",
        "# © MIT 6.S191: Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "\n",
        "!pip install mitdeeplearning -q\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Para converter a notação musical ABC em arquivos de som usaremos:\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qDzmB_sA-hn"
      },
      "source": [
        "## ***Carregando e explorando o dataset da biblioteca do MIT***\n",
        "\n",
        "O MIT 6.S191 disponibiliza um dataset com quase mil músicas folclóricas irlandesas em notação ABC para treinar nosso modelo. Vamos dar uma olhada:\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/irish_folk.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnlmrUkGBHgg"
      },
      "source": [
        "# Podemos carregar os dados e executar as músicas diretamente pelo pacote mdl\n",
        "musicas = mdl.lab1.load_training_data()\n",
        "print(len(musicas))\n",
        "mdl.lab1.play_song(musicas[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUg57xhhhTh7"
      },
      "source": [
        "Vamos olhar a canção mais de perto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAwJIwtshRbB"
      },
      "source": [
        "print(musicas[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHXZXcY3h4XT"
      },
      "source": [
        "Para tornar o dataset um único vetor de dados, podemos unir todos os sons como um objeto de texto. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KRRtvAcitka"
      },
      "source": [
        "todas_musicas = \"\\n\\n\".join(musicas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu0sVIbdnaAa"
      },
      "source": [
        "# ***Processamento dos dados***\n",
        "\n",
        "O processo de treinamento e previsão da RNN exige uma sequência de dados, para que então a rede preveja novos elementos no fim da sequência. Baseado nisso, precisamos transformar os dados em um vetor e ter um meio prático de mapear os caracteres em números e vice-versa (redes neurais treinam e operam apenas com números). Para tal, podemos observar os caracteres exclusivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXF2HHvZusww"
      },
      "source": [
        "vocabulario = sorted(set(todas_musicas))\n",
        "id2char = np.array(vocabulario)\n",
        "char2id = {char:id for id, char in enumerate(vocabulario)}\n",
        "\n",
        "print(f\"{len(vocabulario)} caracteres exclusivos listados abaixo:\")\n",
        "for key, item in char2id.items():\n",
        "  print(f\"({repr(key)}:{item})\", end=\"   \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLKtPGG8VKty"
      },
      "source": [
        "Agora podemos simplesmente mapear o vetor de caracteres para um vetor numérico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufbS5NnCVk0B"
      },
      "source": [
        "todas_musicas_num = np.array(list(map(lambda char: char2id[char], todas_musicas)))\n",
        "print(todas_musicas_num[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9nTccOIYQ8H"
      },
      "source": [
        "Feito isso, precisamos nos lembrar de que a rede terá 'n' inputs, o que significa que o modelo processa 'n' caracteres cada vez, uma sequência. Portanto, precisamos agrupar os dados de treino em partes de comprimento 'n', onde o input será amostrado aleatoriamente enquanto o output será esta mesma sequência, porém deslocado um caractere para a direita. Vejamos um exemplo:\n",
        "\n",
        "*   Se o comprimento desejado for 5:  \n",
        "\n",
        "        'qwerty' -> input='qwert', output='werty'\n",
        "\n",
        "Baseado nisto, podemos criar uma função extratora de lotes (batches), a qual recebe um tamanho de input e um tamanho de lote (batch) para retornar um conjunto de amostras aleatoriamente extraídas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNqBIr5YaVjE"
      },
      "source": [
        "def extrai_batch(dataset, tamanho_input, tamanho_batch):\n",
        "  # o ultimo indice valido nos dados\n",
        "  n = dataset.shape[0] - 1\n",
        "  # indices extraidos aleatoriamente\n",
        "  iea = np.random.choice(n-tamanho_input, tamanho_batch)\n",
        "\n",
        "  # para cada indice, extraimos o input e o output\n",
        "  input_batch = np.array([dataset[i:i+tamanho_input] for i in iea])\n",
        "  output_batch = np.array([dataset[i+1:i+1+tamanho_input] for i in iea])\n",
        "\n",
        "  # para garantir o formato dos batches\n",
        "  x_batch = np.reshape(input_batch, [tamanho_batch, tamanho_input])\n",
        "  y_batch = np.reshape(output_batch, [tamanho_batch, tamanho_input])\n",
        "\n",
        "  return x_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR9xs4Wt0-Eg"
      },
      "source": [
        "# ***O modelo propriamente dito***\n",
        "\n",
        "Com os dados apropriados e a função de extração de lotes, estamos prontos para criar nosso modelo. Nesse projeto em específico, a rede será composta por uma camada de incorporação (embedding layer), uma camada LSTM, e uma camada densa:\n",
        "\n",
        "\n",
        "*   **tf.keras.layers.Embedding:** A camada de incorporação (embedding layer) consiste em mapear os inputs (até então sendo cada caractere representado por um número inteiro) para um vetor numérico de valores reais, similar ao método [one-hot encoding](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd), porém, garantindo que entradas similares sejam representadas por vetores similares, agregando a \"semântica\" das notas ao entendimento da rede. Isto é feito através do processo de aprendizado dos pesos da camada, isto é, a camada atua como uma tabela de pesquisa treinável.\n",
        "*   **tf.keras.layers.LSTM:**  LSTM - Long Short Term Memory - é uma variação de rede neural recorrente a qual lida muito bem com assimilar as relações entre elementos em ordem e distância diferentes na sequência de dados.\n",
        "*   **tf.keras.layers.Dense:** A camada densa compactará os outputs da camada LSTM no comprimento do nosso vocabulário, sendo as saídas desta, a probabilidade log não normalizada para cada categoria, ou seja, quanto maior o número da saída, mais a rede \"pensa\" que o caractere correspondente deveria ser o próximo na sequência - a previsão em si. A ativação softmax não será necessária para converter os valores em sua probabilidade normalizada, uma vez que a função utilizada mais tarde para extrair os caracteres dos outputs lida com os valores crus retirados da rede.\n",
        "\n",
        "Por simplicidade e melhor entendimento, projetaremos o modelo utilizando **tf.keras.Sequential**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UOAshnV0r3I"
      },
      "source": [
        "def cria_modelo(tamanho_vocab: int, embedding_dim: int, nos_rnn: int, tamanho_batch: int) -> tf.keras.Sequential:\n",
        "  \"\"\"\n",
        "  Retorna o modelo de tres camadas.\n",
        "\n",
        "  Inputs:\n",
        "    tamanho_vocab: A dimensao do vocabulario, esto é, quantos caracteres estao sendo considerados.\n",
        "\n",
        "    embedding_dim: A dimensão da camada de incorporacao.\n",
        "\n",
        "    nos_rnn: A dimensao da camada LSTM.\n",
        "\n",
        "    tamanho_batch: O tamanho de cada lote (batch).\n",
        "  \n",
        "  Returno:\n",
        "    modelo: um modelo de tres camadas para problemas sequenciais.\n",
        "  \"\"\"\n",
        "\n",
        "  modelo = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=tamanho_vocab, output_dim=embedding_dim, batch_input_shape=[tamanho_batch, None]),\n",
        "    tf.keras.layers.LSTM(units=nos_rnn, return_sequences=True, recurrent_initializer='glorot_uniform', recurrent_activation='sigmoid', stateful=True),\n",
        "    tf.keras.layers.Dense(units=tamanho_vocab)\n",
        "    ])\n",
        "\n",
        "  return modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4osmVoXsx_g"
      },
      "source": [
        "Podemos então instanciar o modelo e observar sua estrutura."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml0grZ1KByh8"
      },
      "source": [
        "modelo = cria_modelo(len(vocabulario), embedding_dim=256, nos_rnn=1024, tamanho_batch=32)\n",
        "modelo.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYG3GWeWtkNR"
      },
      "source": [
        "Podemos passar uma sequência qualquer pela rede, antes mesmo de treiná-la, apenas para observar as dimensionalidades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_8BL-aBuCth"
      },
      "source": [
        "# Gera um batch de 32 sequencias de 100 caracteres cada\n",
        "x, y = extrai_batch(todas_musicas_num, tamanho_input=100, tamanho_batch=32)\n",
        "\n",
        "# alimenta a rede com os dados (feedforward)\n",
        "predicao_sem_treino = modelo(x)\n",
        "\n",
        "# Agora podemos inspecionar o formato do input (x) e do output (predicao_sem_treino)\n",
        "print(\"Estamos usando um batch de 32 sequencias de 100 caracteres cada:\")\n",
        "print(f\"Forma do Input: {x.shape}\")\n",
        "print(f\"Forma do Output: {predicao_sem_treino.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikqb1cWHvvOH"
      },
      "source": [
        "Portanto, para cada input, existem 83 outputs: uma distribuição de probabilidade log não normalizada sob os possíveis 83 caracteres, onde o maior número pode ser tomado como a previsão da rede. Esta abordagem simples (pegar o argmax) pode levar a um loop, logo é mais adequado amostrar da distribuição:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqAKzRFK44QF"
      },
      "source": [
        "previsao_amostrada = tf.random.categorical(predicao_sem_treino[0], num_samples=1)  # Retorna um tensor com formato (tamanho_input, 1)\n",
        "previsao_amostrada = tf.squeeze(previsao_amostrada)  # então, podemos comprimi-lo em um vetor simples\n",
        "print(previsao_amostrada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTGLWf7jEMoA"
      },
      "source": [
        "Podemos usar nosso decodificador 'id2char' para gerar os caracteres de fato:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTHIAsP4EVbJ"
      },
      "source": [
        "print(repr(\"\".join(id2char[previsao_amostrada])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_yGnG--8fC1"
      },
      "source": [
        "Como os pesos da rede são aleatoriamente inicializados, o output não faz muito sentido, mas já podemos atestar que toda a estrutura do problema está definida e funcionando, então vamos partir para o treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St6x4k8A-DpP"
      },
      "source": [
        "# ***Faça a rede inteligente: treine-a***\n",
        "\n",
        "O processo de treinamento requer uma função de perda (loss function) para informar ao modelo \"o quanto ele está errando\". Para esta tarefa, podemos usar a função *sparse_categorical_crossentropy*, que lida com alvos inteiros (categorias, de 0 a 82).\n",
        "\n",
        "Vamos construir a função de perda para posterior otimização com seu uso:\n",
        "\n",
        "\n",
        "\n",
        "*   ***Labels:*** Classes verdadeiras referentes ao input atual.\n",
        "*   ***Logits:*** Distribuição de probabilidade log não normalizada nas classes referentes ao input atual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVJxIBYd-5NE"
      },
      "source": [
        "def calcula_perda(labels, logits):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=labels, y_pred=logits, from_logits=True)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXVTAPcrPN3R"
      },
      "source": [
        "A função de perda retorna um vetor de perdas, do qual a média significa o custo total. Podemos obter esse custo em nosso modelo ainda sem treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgwkpA6Qm7F"
      },
      "source": [
        "custo_total_sem_treino = calcula_perda(y, predicao_sem_treino).numpy().mean()\n",
        "print(f\"Custo total do batch no modelo ainda sem treinamento: {custo_total_sem_treino}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvx2loz-dJhO"
      },
      "source": [
        "### ***Hiperparâmetros (Hyperparameters)***\n",
        "\n",
        "Além da função de perda, existem muitos hiperparâmetros para serem especificados. Abaixo escolhemos alguns valores coerentes, mas sinta-se livre para tentar outros (de fato, para realmente entender sua influência, você deveria testar vários valores diferentes).\n",
        "\n",
        "&rarr; O processo de otimização requer um critério de parada, que pode ser algo automático (uma perda mínima para a parada do processo), mas em nosso caso, definiremos o número de iterações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awO1ujg3NibX"
      },
      "source": [
        "iteracoes_treino = 2000  # aumente para obter um modelo mais refinado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxBmBrwGODO9"
      },
      "source": [
        "&rarr; A função de extração de lotes requer o tamanho do lote e do input. Quanto maiores estes parâmetros, maior será o custo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS1rSBKtOPrq"
      },
      "source": [
        "tamanho_batch = 4\n",
        "tamanho_input = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlOOOJkyOuEv"
      },
      "source": [
        "&rarr; A taxa de aprendizado é um parâmetro crítico:\n",
        "\n",
        "*   Caso seja muito pequena, a otimização pode ficar presa num ótimo local ruim, levando a resultados do modelo ruins.\n",
        "*   Caso seja muito grande, pode não atingir o ponto de ótimo, ou pode até divergir o processo de otimização.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_NGYh3XQgsh"
      },
      "source": [
        "taxa_aprendizado = 5e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWUthZvKQpdc"
      },
      "source": [
        "&rarr; Usaremos as mesmas dimensões das camadas usadas anteriormente. Esses valores são arbitrários e escolhidos empiricamente: lembre-se de que a arquitetura do modelo não possui regra fixa alguma. Portanto, modelamos pela experiência (sempre respeitando os limites computacionais)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-1ZaKeYS81g"
      },
      "source": [
        "tamanho_vocab = len(vocabulario)\n",
        "embedding_dim = 256 \n",
        "nos_rnn = 1024\n",
        "\n",
        "# instantiate the model\n",
        "modelo = cria_modelo(tamanho_vocab=tamanho_vocab, \n",
        "                  embedding_dim=embedding_dim, \n",
        "                  nos_rnn=nos_rnn, \n",
        "                  tamanho_batch=tamanho_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTYn2v4sdXf-"
      },
      "source": [
        "Finalmente, podemos definir nosso otimizador, o algoritmo que irá aplicar os gradientes na otimização dos pesos da rede. Alguns otimizadores bons e amplamente utilizados são o [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) e o [Adagrad](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad), então vá em frente e tente ambos ou até mesmo os demais disponíveis (para a lista completa visite o [site do TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMYt6U4re0aT"
      },
      "source": [
        "otimizador = tf.keras.optimizers.Adam(taxa_aprendizado)\n",
        "# otimizador = tf.keras.optimizers.Adagrad(taxa_aprendizado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9GyO-6fJG8"
      },
      "source": [
        "# ***A rotina de treinamento***\n",
        "\n",
        "O processo de treinamento será baseado em [GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape), um método de gravação dos gradientes: ao registrar todas as operações de avanço na rede (feedforward - computações que partem do input ao output), podemos calcular os gradientes com a perda na iteração e os pesos atuais. Com este último passo, podemos começar a treinar nossa rede.\n",
        "\n",
        "**Obs**: Podemos acessar os pesos treináveis da rede através de `modelo.trainable_variables`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_xUHFoxiOY-"
      },
      "source": [
        "@tf.function\n",
        "def itera_treino(x, y): \n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = modelo(x)\n",
        "    loss = calcula_perda(y, y_pred)\n",
        "\n",
        "  gradientes = tape.gradient(loss, modelo.trainable_variables)\n",
        "  otimizador.apply_gradients(zip(gradientes, modelo.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWiUtI0SvkHe"
      },
      "source": [
        "# ***Treinando o modelo***\n",
        "\n",
        "Após preparar o campo, o processo de treinamento é simples:\n",
        "\n",
        "1.   Extraia um lote (batch);\n",
        "2.   Calcule a perda (dentro deste passo já está a atualização dos pesos);\n",
        "3.   Adicione a informação da perda à lista de histórico para que a convergência seja posteriormente analisada;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRGQxg0MwDTR"
      },
      "source": [
        "historico = []\n",
        "\n",
        "# Garantindo que o modulo tqdm funcionará adequadamente no notebook\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # limpar as instancias caso existam\n",
        "\n",
        "# Loop de treinamento\n",
        "for iter in tqdm(range(iteracoes_treino)):\n",
        "  x_batch, y_batch = extrai_batch(todas_musicas_num, tamanho_input, tamanho_batch)\n",
        "  loss = itera_treino(x_batch, y_batch)\n",
        "  historico.append(loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DhjM0jTJhJF"
      },
      "source": [
        "Podemos mostrar graficamente o processo de convergência simplesmente plotando o vetor de histórico gerado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GffUEv4MJfVH"
      },
      "source": [
        "# Criando a média móvel do custo total\n",
        "passo = 20\n",
        "media_movel = np.array([np.array(historico[i-passo:i]).mean() for i in range(passo, len(historico))])\n",
        "mm_x = [i for i in range(passo, len(historico))]\n",
        "string = f\"O custo alcança aproximadamente {media_movel[-1]:.2f}\"\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.plot(historico, 'b-', lw=1)\n",
        "ax.plot(mm_x, media_movel, 'r-', lw=2)\n",
        "ax.set_xlabel('Iterações')\n",
        "ax.set_ylabel('Custo total')\n",
        "ax.text(.40, .7, string, transform=ax.transAxes, bbox=dict(facecolor='white', alpha=0), fontsize=15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1b7DuFw2hr"
      },
      "source": [
        "# ***Preparação do modelo***\n",
        "\n",
        "Como a camada de incorporação (embedding layer) é construída com a informação do tamanho de lote, precisamos reconstruir o modelo com um novo `tamanho_lote` de um, devido a utilizarmos apenas um único input para iniciarmos as previsões. Ao reconstruir a rede, todos os parâmetros são reinicializados, e para não perdermos nosso progresso, podemos salvar os pesos para os carregarmos no modelo novo, o qual estará pronto para produção."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX1IqfIsw3NK"
      },
      "source": [
        "# salvando os pesos\n",
        "prefixo_checkpoint = os.path.join('./training_checkpoints', \"my_ckpt\")\n",
        "modelo.save_weights(prefixo_checkpoint)\n",
        "\n",
        "# reconstrua o modelo\n",
        "modelo = cria_modelo(tamanho_vocab=tamanho_vocab, \n",
        "                    embedding_dim=embedding_dim, \n",
        "                    nos_rnn=nos_rnn, \n",
        "                    tamanho_batch=1)\n",
        "\n",
        "# carrega os pesos\n",
        "modelo.load_weights(tf.train.latest_checkpoint('./training_checkpoints'))\n",
        "modelo.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpQrYn6J_5l"
      },
      "source": [
        "Vejamos se mantivemos nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkTVlIUKLJO"
      },
      "source": [
        "modelo.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgJ7FkkCKPr8"
      },
      "source": [
        "# ***Previsão***\n",
        "\n",
        "Nosso modelo está pronto para produção, logo podemos submeter um input inicial e extrair quantas previsões desejarmos com a mesma metodologia: amostrar sob a distribuição de probabilidade das categorias do output. Note que a primeira predição será o input para a seguna predição e assim por diante. O loop completo será:\n",
        "\n",
        "1.   Escolha uma string para começar.\n",
        "2.   Submeta ao modelo e obtenha sua predição.\n",
        "3.   Guarde sua predição.\n",
        "4.   Use a última predição como input.\n",
        "\n",
        "O estado interno da rede é atualizado todo loop, construindo peça a peça uma música nova."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf-i-NP4LWSl"
      },
      "source": [
        "def gera_musicas(modelo, string_inicial, comprimento_predicao):\n",
        "  input = [char2id[s] for s in string_inicial]\n",
        "  input = tf.expand_dims(input, 0)\n",
        "  novos_sons = []\n",
        "\n",
        "  # Reinicia o estado interno do modelo e prepara o módulo tqdm\n",
        "  modelo.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(comprimento_predicao)):\n",
        "\n",
        "    # Extraia as previsoes\n",
        "    predicoes = modelo(input)\n",
        "    predicoes = tf.squeeze(predicoes, 0)\n",
        "    categoria_previsao = tf.random.categorical(predicoes, num_samples=1)[-1,0].numpy()\n",
        "      \n",
        "    # Atualize o input atual\n",
        "    input = tf.expand_dims([categoria_previsao], 0)\n",
        "      \n",
        "    # Adicione o novo caractere\n",
        "    novos_sons.append(id2char[categoria_previsao])\n",
        "    \n",
        "  return (string_inicial + ''.join(novos_sons))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZsAikp8IiT8"
      },
      "source": [
        "Nossa rede artista está pronta, deixe-a compor:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/musician.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCABUCAyIidc"
      },
      "source": [
        "texto_gerado = gera_musicas(modelo=modelo, string_inicial=\"X\", comprimento_predicao=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7NoUr-5NInM"
      },
      "source": [
        "Agora precisamos olhar para padrões que indiquem uma música no texto da saída, o qual pode ser facilmente feito com [expressões regulares](https://docs.python.org/3/library/re.html). Isso é o que a função `mdl.lab1.extract_song_snippet(texto)` faz internamente.\n",
        "\n",
        "Após a extração, podemos tocar, apreciar e até baixar as músicas:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/party_time.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-_aAEEMNIty"
      },
      "source": [
        "sons_gerados = mdl.lab1.extract_song_snippet(texto_gerado)\n",
        "\n",
        "for i, som in enumerate(sons_gerados): \n",
        "  waveform = mdl.lab1.play_song(som)\n",
        "\n",
        "  # Caso o som seja reconhecido, pode ser tocado\n",
        "  if waveform:\n",
        "    print(\"Som \", i)\n",
        "    ipythondisplay.display(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}