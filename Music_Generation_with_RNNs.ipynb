{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation_with_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyAkV+M7rvzucnWclIo4qp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/blob/master/Music_Generation_with_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rklo1xmOBss-"
      },
      "source": [
        "This project is inspired by the MIT 6.S191 2020 course, including the usage of the training set, but it's extremely reproducible with any other dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEMnTfVJy1nY"
      },
      "source": [
        "# ***Recurrent Neural Network as a solution to sequential problems***\n",
        "\n",
        "A sequential problem in the data niche is a problem involving a sequential piece of data of any type - such as an array of information -, where the terms have relations of meaning, state, and order with others. Such a case can carry many issues to machine learning and deep learning standard models, like:\n",
        "\n",
        "*   The sequence **length** can be **variable**.\n",
        "*   The **order** of the terms can be **variable**, changing the sequence meaning/value or not.\n",
        "*   **Important relations** may be **distant** on the sequence, not allowing to consider just a fixed length of every input.\n",
        "*   **One term** can have a **different meaning and/or relevance** depending on its position and/or the other terms themselves.\n",
        "\n",
        "Handling these points allow us many applications, such as \n",
        "climatic forecast,  stock prices prediction, object tracking prediction (essential to autonomous vehicles), text generation, emotion classification, music generation, and many others.\n",
        "\n",
        "   \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/climatic.gif\"> \n",
        "</p>  \n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/stock_prices.png\" width=650>\n",
        "</p> \n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/trajectory_prediction.gif\" width=650>\n",
        "</p>\n",
        "\n",
        "For solving these problems, the RNN process along the sequence, piece by piece, predicting the next element, like the next letter, word, note (in music generation), number, array, etc. With this technique, the backpropagation is made through time, making the internal state of the model (*h*) important for the prediction (*y*).\n",
        "\n",
        "Here is a comparison between the standard network model and a specific RNN architecture - this one will be used in the music generation cause it outputs a sequence of any desired length, but there are many others.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/rnn.jpg\" width=700>\n",
        "</p>\n",
        "\n",
        "So, after training such architecture with music notes, we can predict next notes that never existed, generating a fully new song, a deep learning model composition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az2PKoZc-Vts"
      },
      "source": [
        "# ***Creating the model***\n",
        "\n",
        "Before even starting the project, go to the run option in the toolbar and set the environment to GPU to accelerate the computations.\n",
        "\n",
        "## ***Loading the dependencies:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnfmpTjRy0xc"
      },
      "source": [
        "# specifying tensorflow version\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# importing packages\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "# tqdm module displays a progress bar in our training loop\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for the training set we're gonna use the irish folk songs dataset from MIT 6.S191, under license:\n",
        "\n",
        "# Copyright 2020 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
        "# reference:\n",
        "#\n",
        "# Â© MIT 6.S191: Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "\n",
        "!pip install mitdeeplearning -q\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# for converting the abc notes in song we use\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qDzmB_sA-hn"
      },
      "source": [
        "## ***Loading and exploring the Dataset from the MIT package***\n",
        "\n",
        "The MIT 6.S191 disponibilizes a Dataset with almost a thousand of Irish folk songs already in ABC notation to train our model. Lets look at it:\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/irish_folk.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnlmrUkGBHgg"
      },
      "source": [
        "# we can load the data and play it directly from the mdl package\n",
        "songs = mdl.lab1.load_training_data()\n",
        "print(len(songs))\n",
        "mdl.lab1.play_song(songs[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUg57xhhhTh7"
      },
      "source": [
        "Lets take a closer look to the song."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAwJIwtshRbB"
      },
      "source": [
        "print(songs[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHXZXcY3h4XT"
      },
      "source": [
        "To make a single piece of data, we can join all songs into one text object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KRRtvAcitka"
      },
      "source": [
        "all_songs = \"\\n\\n\".join(songs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu0sVIbdnaAa"
      },
      "source": [
        "# ***Data processing***\n",
        "\n",
        "The RNN training and prediction process requires a sequence of data, so the network will predict new elements at the end of the sequence. Based on this, we need to vectorize the data and have a practical way of mapping the characters into numbers and vice versa. For doing this we can look at the unique characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXF2HHvZusww"
      },
      "source": [
        "unique = sorted(set(all_songs))\n",
        "id2char = np.array(unique)\n",
        "char2id = {char:id for id, char in enumerate(unique)}\n",
        "\n",
        "print(f\"{len(unique)} unique characters listed below:\")\n",
        "for key, item in char2id.items():\n",
        "  print(f\"({repr(key)}:{item})\", end=\"   \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLKtPGG8VKty"
      },
      "source": [
        "Now we can just map the character vector to a numerical vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufbS5NnCVk0B"
      },
      "source": [
        "all_songs_num = np.array(list(map(lambda char: char2id[char], all_songs)))\n",
        "print(all_songs_num[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9nTccOIYQ8H"
      },
      "source": [
        "After that done, we need to remember that our network will have 'n' inputs, which means that the model will process 'n' characters each time, a sequence. Therefore, we need to group the training data into 'n length' pieces, where the input will be randomly sampled while the output will be the same sequence but shifted one character to the right. Let's take an example:\n",
        "\n",
        "*   If the desired legth is 5:  \n",
        "\n",
        "        'qwerty' -> input='qwert', output='werty'\n",
        "\n",
        "\n",
        "Based on that, we can create a batch extractor function, which takes an input size ('n_length') and a batch size to return a randomly extracted set of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNqBIr5YaVjE"
      },
      "source": [
        "def get_batch(all_data, input_size, batch_size):\n",
        "  # the last valid index of the data\n",
        "  n = all_data.shape[0] - 1\n",
        "  # randomly sampled indexes\n",
        "  rsi = np.random.choice(n-input_size, batch_size)\n",
        "\n",
        "  # for each index, we extract the input and output\n",
        "  input_batch = np.array([all_data[i:i+input_size] for i in rsi])\n",
        "  output_batch = np.array([all_data[i+1:i+1+input_size] for i in rsi])\n",
        "\n",
        "  # make sure of the batch format\n",
        "  x_batch = np.reshape(input_batch, [batch_size, input_size])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, input_size])\n",
        "\n",
        "  return x_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR9xs4Wt0-Eg"
      },
      "source": [
        "# ***The model itself***\n",
        "\n",
        "With the proper data and the batch extraction function, we are ready to create the model. In this specific project, the network will be composed of an embedding layer, an LSTM layer, and a dense layer:\n",
        "\n",
        "\n",
        "*   **tf.keras.layers.Embedding:** The embedding layer consists of mapping the input codes into a vector, similar to [one-hot encoding](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd), but making sure that similar codes are represented by similar vectors, which is made by learning the weights of the layer, it is, the embedding layer acts like a trainable lookup table.\n",
        "*   **tf.keras.layers.LSTM:**  LSTM - Long Short Term Memory - is an RNN variation, which deals well with understanding the relations of elements in different orders and distances in the data sequence.\n",
        "*   **tf.keras.layers.Dense:** The dense layer will compact the LSTM layer outputs into our vocabulary length, meaning the unnormalized log-probabilities of each category, it is, the bigger its number, the most the network 'thinks' that a character should be the next - the prediction itself. We won't require softmax activation (normalized probability) due to the function used to extract the value from the output.\n",
        "\n",
        "For simplicity and better understanding, we will design the model with **tf.keras.Sequential**:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UOAshnV0r3I"
      },
      "source": [
        "def our_model(vocab_size: int, embedding_dim: int, rnn_units: int, batch_size: int) -> tf.keras.Sequential:\n",
        "  \"\"\"\n",
        "  Returns the three-layered model.\n",
        "\n",
        "  Inputs:\n",
        "    vocab_size: the size of our vocabulary, it is, how many characters are being considered.\n",
        "\n",
        "    embedding_dim: the dense embedding dimension.\n",
        "\n",
        "    rnn_units: the LSTM layer dimension.\n",
        "\n",
        "    batch_size: the size of each batch.\n",
        "  \n",
        "  Returns:\n",
        "    model: a three-layered model for sequential problems.\n",
        "  \"\"\"\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(units=rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform', recurrent_activation='sigmoid', stateful=True),\n",
        "    tf.keras.layers.Dense(units=vocab_size)\n",
        "    ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4osmVoXsx_g"
      },
      "source": [
        "We can then instantiate the model and see its structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml0grZ1KByh8"
      },
      "source": [
        "model = our_model(len(unique), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYG3GWeWtkNR"
      },
      "source": [
        "We can pass an aleatory sequence in the network, even without training, just for looking at the dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_8BL-aBuCth"
      },
      "source": [
        "# generate a batch of 32 sequences of 100 characters each\n",
        "x, y = get_batch(all_songs_num, input_size=100, batch_size=32)\n",
        "\n",
        "# feedforward the training set\n",
        "no_training_predic = model(x)\n",
        "\n",
        "# now we can inspect the shape of the input (x) and the output (no_training_predic)\n",
        "print(\"We're using a batch of 32 sequences of 100 characters each:\")\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {no_training_predic.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikqb1cWHvvOH"
      },
      "source": [
        "Thus, for each input sequence, there are 83 outputs: an unnormalized distribution of log-probability over the 83 possible characters, where the bigger output can be taken as the network prediction. This simple approach (take the argmax) can lead to a loop, so it's more adequate to sample from the distribution: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqAKzRFK44QF"
      },
      "source": [
        "sampled_predictions = tf.random.categorical(no_training_predic[0], num_samples=1)  # returns a tensor with (input_size, 1) shape\n",
        "sampled_predictions = tf.squeeze(sampled_predictions)  # so, we can squeeze it to a simple array\n",
        "print(sampled_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTGLWf7jEMoA"
      },
      "source": [
        "We can use our decoder 'id2char' for generating the actual characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTHIAsP4EVbJ"
      },
      "source": [
        "print(repr(\"\".join(id2char[sampled_predictions])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_yGnG--8fC1"
      },
      "source": [
        "As the weights of the network are randomly initialized, the output doesn't make much sense, but we can see that the whole structure of the problem is now defined and working, so let's train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St6x4k8A-DpP"
      },
      "source": [
        "# ***Make the network smart: train it***\n",
        "\n",
        "The training process requires a loss function to inform the model \"how much it is doing wrong.\" For this task, we can use a *sparse_categorical_crossentropy* loss, which deals with integer targets (categories).\n",
        "\n",
        "Let's build the loss function for later optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVJxIBYd-5NE"
      },
      "source": [
        "def compute_loss(labels, logits):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=labels, y_pred=logits, from_logits=True)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXVTAPcrPN3R"
      },
      "source": [
        "The loss function returns a vector of losses, which we can take the average for having the total cost. We can see this cost on our untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgwkpA6Qm7F"
      },
      "source": [
        "total_cost_untrained = compute_loss(y, no_training_predic).numpy().mean()\n",
        "print(f\"Total cost of the batch on the untrained model: {total_cost_untrained}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvx2loz-dJhO"
      },
      "source": [
        "### ***Hyperparameters***\n",
        "\n",
        "Besides the loss function, there are a lot of hyperparameters to specify. Below we chose some reasonable values, but feel free to try others (in fact, for really understanding their influence, you should test a lot of different values).\n",
        "\n",
        "&rarr; The optimization process needs a stop condition, which may be something automatic (a loss threshold), but in our case, we will set the number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awO1ujg3NibX"
      },
      "source": [
        "num_training_iterations = 2000  # increase for a most tuned model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxBmBrwGODO9"
      },
      "source": [
        "&rarr; The bacth extraction function requires the batch size and the input size. The bigger those parameters, the higher the computational cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS1rSBKtOPrq"
      },
      "source": [
        "batch_size = 4\n",
        "seq_length = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlOOOJkyOuEv"
      },
      "source": [
        "&rarr; The learning rate is a critical parameter:\n",
        "\n",
        "*   If too small, can get stuck in bad local optima, resulting in bad model results.\n",
        "*   If too big, can not reach the optimal point, or can even diverge the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_NGYh3XQgsh"
      },
      "source": [
        "learning_rate = 5e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWUthZvKQpdc"
      },
      "source": [
        "&rarr; We are going to use the same previous values for the dimensions of the layers. These values are arbitrary and empirically chosen: remember that the model architecture has no fixed rule. Therefore, we model it by experience (always respecting the computational limits)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-1ZaKeYS81g"
      },
      "source": [
        "vocab_size = len(unique)\n",
        "embedding_dim = 256 \n",
        "rnn_units = 1024\n",
        "\n",
        "# instantiate the model\n",
        "model = our_model(vocab_size=vocab_size, \n",
        "                  embedding_dim=embedding_dim, \n",
        "                  rnn_units=rnn_units, \n",
        "                  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTYn2v4sdXf-"
      },
      "source": [
        "Finally, we can define our optimizer, the algorithm that will apply our gradients in the weights optimization. Some good and widely used optimizers are [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and [Adagrad](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad), so go ahead and try both yourself or even other optimizers (for the full list visit [the TensorFlow website](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMYt6U4re0aT"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "# optimizer = tf.keras.optimizers.Adagrad(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9GyO-6fJG8"
      },
      "source": [
        "# ***The training routine***\n",
        "\n",
        "The training process will be based on [GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape), a gradient recording method: by recording all forward operations, we can calculate the gradients with the weights and the loss. With this last step, we can start training our model.\n",
        "\n",
        "**Note**: We can access the trainable weights by `model.trainable_variables`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_xUHFoxiOY-"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y): \n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(x)\n",
        "    loss = compute_loss(y, y_pred)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWiUtI0SvkHe"
      },
      "source": [
        "# ***Train the model***\n",
        "\n",
        "After preparing the field, the training process is simple:\n",
        "\n",
        "\n",
        "1.   Extract a batch;\n",
        "2.   Calculate the loss (inside this step is already the weights actualization);\n",
        "3.   Add the loss information to a history list for later analysis of the convergence;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRGQxg0MwDTR"
      },
      "source": [
        "history = []\n",
        "\n",
        "# ensuring tqdm will work well\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "# training loop\n",
        "for iter in tqdm(range(num_training_iterations)):\n",
        "  x_batch, y_batch = get_batch(all_songs_num, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "  history.append(loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DhjM0jTJhJF"
      },
      "source": [
        "We can show the training process convergence simply by plotting the history list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GffUEv4MJfVH"
      },
      "source": [
        "# Creating a moving average of the losses\n",
        "step = 20\n",
        "moving_average = np.array([np.array(history[i-step:i]).mean() for i in range(step, len(history))])\n",
        "ma_x = [i for i in range(step, len(history))]\n",
        "string = f\"The cost reaches approximately {moving_average[-1]:.2f}\"\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.plot(history, 'b-', lw=1)\n",
        "ax.plot(ma_x, moving_average, 'r-', lw=2)\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_ylabel('Total Cost')\n",
        "ax.text(.40, .7, string, transform=ax.transAxes, bbox=dict(facecolor='white', alpha=0), fontsize=15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1b7DuFw2hr"
      },
      "source": [
        "# ***Model preparing***\n",
        "\n",
        "As the embedding layer is built with the batch size information, we need to rebuild the model, passing a new batch size of 1, due to having a single input for starting the prediction. By rebuilding the network, all parameters are reinitialized, and to don't lose the progress, we can save the weights for loading them into the fresh model, which will be ready for production then."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX1IqfIsw3NK"
      },
      "source": [
        "# saving the weights\n",
        "checkpoint_prefix = os.path.join('./training_checkpoints', \"my_ckpt\")\n",
        "model.save_weights(checkpoint_prefix)\n",
        "\n",
        "# rebuilding the model\n",
        "model = our_model(vocab_size=vocab_size, \n",
        "                    embedding_dim=embedding_dim, \n",
        "                    rnn_units=rnn_units, \n",
        "                    batch_size=1)\n",
        "\n",
        "# reloading the weights\n",
        "model.load_weights(tf.train.latest_checkpoint('./training_checkpoints'))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpQrYn6J_5l"
      },
      "source": [
        "Let's see if we maintained our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkTVlIUKLJO"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgJ7FkkCKPr8"
      },
      "source": [
        "# ***Prediction***\n",
        "\n",
        "Our model is ready for production, so we can input a starting point and extract as many predictions as we want with the same methodology: sample from the output categories probability distribution. Notice that our first prediction must be the input for the second prediction and so on. The full loop will be:\n",
        "\n",
        "\n",
        "1.   Chose a starting string.\n",
        "2.   Run it on the model and obtain its prediction.\n",
        "3.   Store this prediction.\n",
        "4.   Use the last prediction as input.\n",
        "\n",
        "The internal state of the network is actualized every loop, building piece by piece a fresh new song track."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf-i-NP4LWSl"
      },
      "source": [
        "def generate_song(model, start_string, new_song_length):\n",
        "  input = [char2id[s] for s in start_string]\n",
        "  input = tf.expand_dims(input, 0)\n",
        "  new_songs = []\n",
        "\n",
        "  # reset the model internal state and prepare tqdm module\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(new_song_length)):\n",
        "\n",
        "    # Extract the prediction\n",
        "    predictions = model(input)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predicted_category = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      \n",
        "    # Update the actual input\n",
        "    input = tf.expand_dims([predicted_category], 0)\n",
        "      \n",
        "    # Add the new character\n",
        "    new_songs.append(id2char[predicted_category])\n",
        "    \n",
        "  return (start_string + ''.join(new_songs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZsAikp8IiT8"
      },
      "source": [
        "Our artist network is ready, let it compose:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/musician.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCABUCAyIidc"
      },
      "source": [
        "generated_text = generate_song(model=model, start_string=\"X\", new_song_length=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7NoUr-5NInM"
      },
      "source": [
        "Now we need to look for patterns that indicate a song in the outputted text, which can be easily done with [regular expressions](https://docs.python.org/3/library/re.html). That is what `mdl.lab1.extract_song_snippet(text)` internally does.\n",
        "\n",
        "After extracted, we can play, enjoy and even download:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/RodrigoMarquesP/Music_Generation_with_Recurrent_Neural_Networks-An_AI_Composer/master/files/party_time.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-_aAEEMNIty"
      },
      "source": [
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs): \n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If there's any recognized song, play it\n",
        "  if waveform:\n",
        "    print(\"Song \", i)\n",
        "    ipythondisplay.display(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
